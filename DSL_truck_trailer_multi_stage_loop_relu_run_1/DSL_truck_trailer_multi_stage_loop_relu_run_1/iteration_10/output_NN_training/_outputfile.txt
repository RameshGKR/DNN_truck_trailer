units: 64.0
activation_function: relu
learning_rate: 0.0008554203265372855
hidden_layers: 4.0
The amount of trained epochs are: 300
The loss function is: mean_squared_error
Model: "sequential_1"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 dense_5 (Dense)             (None, 64)                320       
                                                                 
 dense_6 (Dense)             (None, 64)                4160      
                                                                 
 dense_7 (Dense)             (None, 64)                4160      
                                                                 
 dense_8 (Dense)             (None, 64)                4160      
                                                                 
 dense_9 (Dense)             (None, 3)                 195       
                                                                 
=================================================================
Total params: 12,995
Trainable params: 12,995
Non-trainable params: 0
_________________________________________________________________
